{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vid-Math/DeepLearning/blob/main/DNN_boilerplate_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "eatd_MK1leSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ycvvjf4Iw2nc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras import Input\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Sequential Model"
      ],
      "metadata": {
        "id": "517QIYKpfVuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential Model - layers of neural network are stacked sequentially. The approach:\n",
        "1.  Implement a class to build a dense layer (NaiveDense)\n",
        "2.  Stack the layers sequentially and build or suquential model (NaiveSequential)\n"
      ],
      "metadata": {
        "id": "_Tdm4MV4T7ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implemnting dense layer class\n",
        "class NaiveDense:\n",
        "  def __init__(self, input_size, output_size, activation):  #input and output sizes for the layer\n",
        "    self.activation = activation\n",
        "\n",
        "    w_shape = (input_size, output_size)       # matrix of weights\n",
        "    w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "    self.w = tf.Variable(w_initial_value)     # we can only update values of tf.Variables\n",
        "\n",
        "    b_shape = (output_size,)                  # vector of biases\n",
        "    b_initial_value = tf.zeros(b_shape)\n",
        "    self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "  def __call__(self, inputs):                 # executed when the class object is used as a function\n",
        "    return self.activation(tf.matmul(inputs, self.w)+self.b)      # self.b is broadcasted\n",
        "\n",
        "  @property                                   # enables us to use the method as an attribute\n",
        "  def weights(self):\n",
        "    return (self.w, self.b)"
      ],
      "metadata": {
        "id": "xpdyi8kVw-zz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now stacking them together sequentially in NaiveSequential class"
      ],
      "metadata": {
        "id": "zggIWLcPbj-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveSequential:\n",
        "  def __init__(self,layers):    # layers: list of layer objects\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, inputs):   \n",
        "    x = inputs\n",
        "    for layer in self.layers:     #ouptut of the prev layer is the input to the next layer\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  @property\n",
        "  def weights(self):\n",
        "    weights = []\n",
        "    for layer in self.layers:     # save weights of each layer to a list\n",
        "      weights += layer.weights    # Q: What does layer.weights return? \n",
        "    return weights                # A: layer.weights calls the function layer.weights() since it decorated with @property. It returns (w,b)\n",
        "\n"
      ],
      "metadata": {
        "id": "0kA-qPdezucM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iinstantiate our NaiveSequential class and make first NN model"
      ],
      "metadata": {
        "id": "6WNsmMS1dlKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "# input to the model - layers (NaiveDense)\n",
        "model = NaiveSequential([\n",
        "        NaiveDense(input_size=28*28,output_size=512,activation=tf.nn.relu), #input dim = 28*24 = 784\n",
        "        NaiveDense(input_size=512,output_size=10,activation=tf.nn.softmax)  #output dim = 10 \n",
        "])"
      ],
      "metadata": {
        "id": "d6D514nbI_-h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's solve a calssification problem by using above sequential model for [MNIST data set](https://keras.io/api/datasets/mnist/). \n",
        "\n",
        "Steps followed:\n",
        "1. Load the data, \n",
        "2. Reshape the data according to the input shape of the model and \n",
        "3. Normalize the data"
      ],
      "metadata": {
        "id": "elt6Stitd89N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "print(f\"train_images.shape = {train_images.shape}\")\n",
        "print(f\"train_labels.shape = {train_labels.shape}\")\n",
        "\n",
        "idx = 7\n",
        "plt.imshow(train_images[idx])\n",
        "print(f\"label for image id {idx}: \",train_labels[idx])\n"
      ],
      "metadata": {
        "id": "VI9typezHEjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "db673a5b-3d1a-479b-ef15-8ce4c5e5489f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "train_images.shape = (60000, 28, 28)\n",
            "train_labels.shape = (60000,)\n",
            "label for image id 7:  3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape and normalize data\n",
        "train_images = train_images.reshape((len(train_images),\n",
        "                                     28*28)).astype(\"float32\")/255\n",
        "test_images = test_images.reshape((len(test_images),\n",
        "                                     28*28)).astype(\"float32\")/255\n",
        "\n",
        "print(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx1EX8vEc4xJ",
        "outputId": "5ff42bcc-d1e5-40f3-afad-edf937c78872"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 0 4 ... 5 6 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we divide the data into batches. For this operation let's implement a class for Batch Generation."
      ],
      "metadata": {
        "id": "tkUUYF4Ye4_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchGenerator:\n",
        "\n",
        "  def __init__(self, images, labels, batch_size=128):\n",
        "    assert len(images) == len(labels)\n",
        "    self.index = 0\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.num_batches = math.ceil(len(images)/batch_size)\n",
        "    print(f\"batch size = {batch_size}\")\n",
        "    print(f\"num of batches = {self.num_batches}\")\n",
        "\n",
        "  def next(self):\n",
        "    images = self.images[self.index:self.index + self.batch_size]\n",
        "    labels = self.labels[self.index:self.index + self.batch_size]\n",
        "    self.index += self.batch_size\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "5GXARTD3uDNr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Training steps:*\n",
        "\n",
        "1. Compute the predictions using current weights (Forward Pass).\n",
        "2. Compute the loss value for these predictions.\n",
        "3. Compute the gradient with respect to model weights.\n",
        "4. update the weights."
      ],
      "metadata": {
        "id": "UgMQxpCtDyA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one_training_step function gives the idea of how loss is computed and layer \\\n",
        "# parameters (weights and biases) are updated\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "  with tf.GradientTape() as tape:                   # GradientTape() is the computational graph \n",
        "    predictions = model(images_batch)               # forward pass.  - step1\n",
        "    per_sample_losses = keras.losses.sparse_categorical_crossentropy(  # define loss - step2\n",
        "        labels_batch, predictions\n",
        "    )\n",
        "    average_loss = tf.reduce_mean(per_sample_losses)  \n",
        "  gradients = tape.gradient(average_loss, model.weights)      # Compute gradients - step 3\n",
        "  update_weights(gradients, model.weights)                    # Update the weights - step 4 learning is happening\n",
        "  return average_loss\n",
        "\n",
        "learning_rate = 1e-3\n",
        "def update_weights(gradients, weights):\n",
        "  for g,w in zip(gradients, weights):\n",
        "    w.assign_sub(g*learning_rate)             # w -= g*lr\n",
        "    \n",
        "# Full training loop\n",
        "# one loop for mini batch and then for another batch\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "  for epoch in range(epochs):                       # repeat for epochs\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    batch_generator = BatchGenerator(images, labels)\n",
        "    for batch_counter in range(batch_generator.num_batches):      # go through all mini-batches in the data\n",
        "      images_batch, labels_batch = batch_generator.next()\n",
        "      loss = one_training_step(model, images_batch, labels_batch)\n",
        "      if batch_counter%100 == 0:\n",
        "        print(f\"loss at batch {batch_counter}:{loss:.2f}\")\n"
      ],
      "metadata": {
        "id": "aFh4xHf3DuHT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's train the model on MNIST data set."
      ],
      "metadata": {
        "id": "fi3VZPlPg1KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oHVb61nItzQ",
        "outputId": "0ac6cc2d-e7b9-4cf9-bc55-76e4fa8da6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:6.04\n",
            "loss at batch 100:2.23\n",
            "loss at batch 200:2.19\n",
            "loss at batch 300:2.09\n",
            "loss at batch 400:2.24\n",
            "Epoch 1\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:1.93\n",
            "loss at batch 100:1.88\n",
            "loss at batch 200:1.82\n",
            "loss at batch 300:1.73\n",
            "loss at batch 400:1.85\n",
            "Epoch 2\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:1.61\n",
            "loss at batch 100:1.58\n",
            "loss at batch 200:1.49\n",
            "loss at batch 300:1.44\n",
            "loss at batch 400:1.52\n",
            "Epoch 3\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:1.35\n",
            "loss at batch 100:1.34\n",
            "loss at batch 200:1.22\n",
            "loss at batch 300:1.22\n",
            "loss at batch 400:1.27\n",
            "Epoch 4\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:1.14\n",
            "loss at batch 100:1.15\n",
            "loss at batch 200:1.03\n",
            "loss at batch 300:1.05\n",
            "loss at batch 400:1.10\n",
            "Epoch 5\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:0.99\n",
            "loss at batch 100:1.01\n",
            "loss at batch 200:0.89\n",
            "loss at batch 300:0.93\n",
            "loss at batch 400:0.98\n",
            "Epoch 6\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:0.88\n",
            "loss at batch 100:0.90\n",
            "loss at batch 200:0.78\n",
            "loss at batch 300:0.84\n",
            "loss at batch 400:0.89\n",
            "Epoch 7\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:0.80\n",
            "loss at batch 100:0.82\n",
            "loss at batch 200:0.71\n",
            "loss at batch 300:0.77\n",
            "loss at batch 400:0.82\n",
            "Epoch 8\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:0.74\n",
            "loss at batch 100:0.75\n",
            "loss at batch 200:0.64\n",
            "loss at batch 300:0.71\n",
            "loss at batch 400:0.77\n",
            "Epoch 9\n",
            "batch size = 128\n",
            "num of batches = 469\n",
            "loss at batch 0:0.68\n",
            "loss at batch 100:0.70\n",
            "loss at batch 200:0.60\n",
            "loss at batch 300:0.66\n",
            "loss at batch 400:0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Evaluation step\n",
        "predictions = model(test_images).numpy()\n",
        "predicted_labels = np.argmax(predictions,axis=1) \n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy:{matches.mean():.2f}\")\n",
        "print(predictions.shape)\n",
        "print(predicted_labels)\n",
        "print(matches)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0r_RULJJazg",
        "outputId": "a822afd2-14e6-4cf6-8d90-7d7e58b278f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:0.81\n",
            "(10000, 10)\n",
            "[7 3 1 ... 4 8 6]\n",
            "[ True False  True ...  True False  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "plt.imshow(test_images[idx].reshape(28,28))\n",
        "print(predicted_labels[idx], test_labels[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8sXg7ZEGjiai",
        "outputId": "9fa8dd06-fc88-478a-dfc4-2050d21247a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2b9oQbzWHcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}